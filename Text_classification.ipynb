{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title << Setup Google Colab by running this cell {display-mode: \"form\"}\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    # Clone GitHub repository\n",
    "    !git clone https://github.com/epfl-exts/amld20-text-classification.git\n",
    "        \n",
    "    # Copy files required to run the code\n",
    "    !cp -r \"amld20-text-classification/data\" \"amld20-text-classification/tools.py\" .\n",
    "    \n",
    "    # Install packages via pip\n",
    "    !pip install -r \"amld20-text-classification/colab-requirements.txt\"\n",
    "    \n",
    "    # Restart Runtime\n",
    "    import os\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification :: Spam detection\n",
    "\n",
    "## Task \n",
    "\n",
    "We want to build a Spam detector which, given examples of spam emails (e.g. flagged by users) and examples of regular (non-spam, also called \"ham\") emails, learns how to flag new unseen emails as spam or non-spam.\n",
    "\n",
    "## Data\n",
    "\n",
    "We will use the [SpamAssassin](https://spamassassin.apache.org/) public email corpus. This dataset contains ~6'000 labeled emails with a ~30% spam ratio. If you want to learn more about this dataset, check [this](https://spamassassin.apache.org/old/publiccorpus/). (*Note: Datasets of text are called corpora and samples are called documents.*) \n",
    "\n",
    "The dataset has been downloaded for you and is available in the *data* folder.\n",
    "\n",
    "## Notebook overview\n",
    "\n",
    "* Load the data\n",
    "* Text preprocessing\n",
    "* Data exploration\n",
    "* Feature extraction\n",
    "* Build a spam detector\n",
    "* What did our model learn? Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and helper functions\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "df = tools.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a few rows from the dataset.\n",
    "\n",
    "***Note:*** *label* is 0 for *non-spam* and 1 for *spam*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check the number of samples per class in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_class_frequency(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text preprocessing\n",
    "\n",
    "Good text preprocessing is an essential part of every NLP project!\n",
    "\n",
    "Our goal here is to build a model that distinguishes non-spam from spam. The idea here is to \"clean\" and \"standardize\" raw text before feeding it to our machine learning model. We need to keep as many \"informative\" words as possible, while discarding the \"uniformative\" ones. Removing unnecessary content, i.e. the \"noise\", from our texts will help to improve the accuracy of our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a few minutes to look at the raw text. What do you think should be removed from the text?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a few pointers:\n",
    "\n",
    "* HTML tags \n",
    "* URLs\n",
    "* E-mail addresses\n",
    "* Punctuation marks, digits (e.g. 2002, 1.1, ...)\n",
    "* Multiple whitespace\n",
    "* Case conversion (e.g. Dog vs dog, ...)\n",
    "* English STOPWORDS (e.g. a, is, my, i, all, and, by...)\n",
    "* ...\n",
    "\n",
    "The *clean_corpus* function below takes care of all of that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tools.clean_corpus(df)\n",
    "\n",
    "print('Data cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a few \"cleaned\" examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.show_clean_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration :: What makes spam distinct?\n",
    "\n",
    "### 2.1 Frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which words distinguish spam from non-spam? Can we  identify the words in a text that are the most informative about its topic?\n",
    "\n",
    "Let's find the most frequent words in spam and non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_most_common_words(df=df, N=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequent \"spammish\" words**: \n",
    "\n",
    "* click\n",
    "* money\n",
    "* business\n",
    "* free\n",
    "* email\n",
    "* ...\n",
    "\n",
    "**Frequent \"non-spammish\" words**:\n",
    "* list\n",
    "* linux\n",
    "* message\n",
    "* wrote\n",
    "* users\n",
    "* spam\n",
    "* said\n",
    "* file\n",
    "* good\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 What about \"spammish\" signatures?\n",
    "\n",
    "* Do spams contain more HTML tags? \n",
    "* Does non-spam contain more URLs and E-mail adresses? \n",
    "* Are spams mails longer than non-spam? \n",
    "* ...\n",
    "\n",
    "Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tools.get_features(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature engineering :: Extracting features from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers don't understand natural language. So, how do we represent text?\n",
    "\n",
    "One of the simplest but effective and commonly used models to represent text for machine learning is the ***Bag of Words*** model ([online documentation](https://en.wikipedia.org/wiki/Bag-of-words_model)). When using this model, we discard most of the structure of the input text (word order, chapters, paragraphs, sentences and formating) and only count how often each word appears in each text. Discarding the structure and counting only word occurencies leads to the mental image of representing text as a \"bag\".  \n",
    "\n",
    "**Example:** Let our toy corpus contain four documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ corpus = ['I\\;enjoy\\;paragliding.',  $  \n",
    "$\\hspace{2cm}'I\\;like\\;NLP.',$  \n",
    "$\\hspace{2cm}'I\\;like\\;deep\\;learning.',$  \n",
    "$\\hspace{2cm}'O\\;Captain!\\;my\\;Captain!']$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.show_bag_of_words_vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words has converted all documents into numeric vectors. Each column represents a word from the corpus and each row one of the four documents. The value in each cell represents the number of times that word appears in a specific document. For example, the fourth document has the word `captain` occuring twice and the words `my` and `O` occuring once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build a spam detector\n",
    "\n",
    "In the previous section, we saw how to perform text preprocessing and feature extraction from text. We are now ready to build our machine learning model for detecting spams. We will use a Logistic Regression classifier ([online documentation](https://en.wikipedia.org/wiki/Logistic_regression)).\n",
    "\n",
    "First, we need to split the data into two sets: the `train` set and the `test` set. We will then use the train set to `fit` our model. The test set will be used to `evaluate` the performance of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Spam classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test splitting\n",
    "df_train, df_test = tools.train_test_split_(df)\n",
    "\n",
    "# Fit model on the train data\n",
    "model = tools.fit_model(df_train)\n",
    "\n",
    "# Print predictions on test set\n",
    "tools.plot_confusion_matrix(df_test,model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrices**  \n",
    "\n",
    "Confusion matrices are a nice way of evaluating the performance of models for classification models. Rows correspond to the true classes and the columns to the predicted classes. Entries on the main diagonal of the confusion matrix correspond to correct predictions while the other cells tell us how many mistakes made our model ([online documentation]((https://en.wikipedia.org/wiki/Confusion_matrix))).\n",
    "\n",
    "* The first row represents non-spam mails: 1'187 were correctly classified as 'non-spam', while 29 (~2,3%) were misclassified as 'spam'.\n",
    "* The second row represents spam mails: 437 were correctly classified as 'spam', while 13 (~2,8%) were misclassified as 'non-spam'.\n",
    "\n",
    "Our model did quite well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 What did our model learn from the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our logistic regression model has learned which words are the most indicative of non-spam and which words are the most indicative of spam. The positive coefficients on the right correspond to words that, according to the model, are indicative of spam. The negative coefficients on the left correspond to words that, according to the model, are indicative of non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.visualize_coefficients(model, n_top_features=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the model, words such as \"date\", \"wrote\", \"yahoo\", \"said\", \"linux\", \"author\", ... are strong indicators of non-spam.  \n",
    "\n",
    "Words such as \"click\", \"credit\", \"remove\", \"free\", \"offer\", \"money\" ... indicate spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Error analysis :: Where does our model fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now analyze the misclassified mails in order to get some insights on where the model failed to make correct predictions. The *error_analysis* function below will show us the top features responsible for the model making a decision of prediction whether the mail is spam or non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.error_analysis(df_test,model,doc_nbr=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
